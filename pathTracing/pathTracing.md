## 图形管线



## 渲染管线

https://positiveczp.github.io/%E7%BB%86%E8%AF%B4%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF.pdf

渲染管线的功能是通过给定虚拟相机、3D场景物体以及光源等场景要素来产生或者渲染一副2D的图像。

![图形管线](/Users/lingxin/Desktop/pathTracing/图形管线.png)

如上图所示，场景中的3D物体通过管线转变为屏幕上的2D图像。图形渲染管线主要包括两个功能：一是将物体3D坐标转变为屏幕空间2D坐标，二是为屏幕每个像素点进行着色。渲染管线的一般流程如下图所示。分别是：顶点数据的输入、顶点着色器、曲面细分过程、几何着色器、图元组装、裁剪剔除、光栅化、片段着色器以及混合测试。

渲染管线的一个特点就是每个阶段都会把前一个阶段的输出作为该阶段的输入。例如，片段着色器会将光栅化后的片段(以及片段的数据块)作为输入进行光照计算。除了图元组装和光栅化几个阶段是由硬件自动完成之外，管线的其他阶段管线都是可编程/可配置的。其中顶点着色器、曲面细分相关着色器、几何着色器和片段着色器是可编程的阶段，而混合测试是可高度配置的阶段。管线的可编程/可配置是渲染管理的另一个特点。因为早期的渲染管线采用的是立即渲染模式(Immediatemode，也就是固定渲染管线)，不允许开发人员改变GPU渲染的方式，而核心渲染默认(Core-profilemode)允许开发人员定制化GPU的渲染方式。渲染流水线具体流程如下图：

![渲染流水线](/Users/lingxin/Desktop/pathTracing/渲染流水线.png)

我们接下来简单介绍管线各个阶段的功能：

**顶点数据**：顶点数据用来为后面的顶点着色器等阶段提供处理的数据。是渲染管线的数据主要来源。送入到渲染管线的数据包括顶点坐标、纹理坐标、顶点法线和顶点颜色等顶点属性。为了让OpenGL明白顶点数据构成的是什么图元，我们需要在绘制指令中传递相对应的图元信息。常见的图元包括：点(GL_POINTS)、线(GL_LINES)、线条(GL_LINE_STRIP)、三角面(GL_TRIANGLES)。

> **坐标变换**：
>
> 顶点着色器用来处理输入的顶点数据，主要用来进行顶点坐标变换以及顶点着色。我们知道，从输入的顶点局部坐标到最终的屏幕坐标需要经过一系列的坐标变换，才能最终显示到屏幕上。下面的图片展示了顶点坐标的一系列变换过程。我们从建模工具得到的是物体的局部坐标(LocalCoordinate)，局部坐标通过模型矩阵Model变换到世界坐标(WorldCoordinate)，世界坐标通过观察矩阵View变换到观察坐标(ViewCoordinate)，观察坐标经过投影矩阵Projection变换到裁剪坐标(ClipCoordinate)，裁剪坐标经过透射除法(PerspectiveDivision)得到标准设备空间(NormalizedDeviceCoordinates，NDC)，NDC坐标通过视口变换(ViewportTransformation)变换到窗口坐标进行显示。
>
> ![坐标变换](/Users/lingxin/Desktop/pathTracing/坐标变换.png)
>
> 我们知道，光照计算一般都是在世界空间进行的，所以输入的顶点坐标需要通过乘以模型矩阵变换到世界空间。
>
> 虚拟相机定义了我们的观察空间。世界空间和观察空间的关系如下所示，虚拟摄像机的位置是坐标的原点，观察方向沿着Z轴的负方向。我们可以通过摄像机的位置EyePosition、观察目标点FocusPosition和向上的方向向量UpDirection来构建观察矩阵。
>
> ![观察矩阵](/Users/lingxin/Desktop/pathTracing/观察矩阵.png)
>
> 介绍裁剪空间之前，我们需要先来看一个重要的概念：视椎体(Frustum)。视椎体可以通过上下左右远近六个平面来定义。我们通过投影矩阵将物体从观察空间变换到裁剪空间，裁剪空间是一个以原点为中心的立方体，不在该裁剪空间的图元都会被裁剪。根据投影方式的不一样，我们可以定义不同的投影矩阵，常见的投影方法有：正交投影和透视投影。下图展示两种投影的视锥体。我们可以看到正交投影的视椎体是长方体，而透视投影的视椎体是台体。我们可以通过近平面(Near)、远平面(Far)、垂直视场角(VerticalFieldofView，FOV)和屏幕纵横比(AspectRatio，也叫作屏幕宽高比)四个参数来定义视椎体。
>
> ![视锥体](/Users/lingxin/Desktop/pathTracing/视锥体.png)
>
> 正交投影又叫平行投影。投影视椎体是一个长方体，物体在投影平面的大小与距离远近没有关系。通过正交矩阵变换后，我们得到了裁剪空间。建筑蓝图绘制和计算机辅助设计需要使用到正交投影，因为这些行业要求投影后的物体尺寸及相互间的角度不变，以便施工或制造时物体比例大小正确。
>
> 根据我们的生活经验我们会发现这样的现象，离你越远的物体看起来越小，随着距离的增大，最终会消失在视野中。为了实现这种近大远小的效果，我们需要引入透视投影。投影变换使用的是齐次坐标，因为在透视除法阶段需要将XYZ的值除以W分量来获取NDC坐标空间。透视除法可以实现近大远小的视觉效果，该过程由硬件自动执行。这也是正交变换和透视变换最主要的区别。

**顶点着色器**：顶点着色器主要功能是进行坐标变换。将输入的局部坐标变换到世界坐标、观察坐标和裁剪坐标。***虽然我们也会在顶点着色器进行光照计算(称作高洛德着色)***，然后经过光栅化插值得到各个片段的颜色，但由于这种方法得到的光照比较不自然，所以一般在片段着色器进行光照计算。

**曲面细分**：曲面细分是利用镶嵌化处理技术对三角面进行细分，以此来增加物体表面的三角面的数量，是渲染管线一个可选的阶段。它由外壳着色器(HullShader)、镶嵌器(Tessellator)和域着色器(DomainShader)构成，其中外壳着色器和域着色器是可编程的，而镶嵌器是有硬件管理的。我们可以借助曲面细分的技术实现细节层次(Level-ofDetail)的机制，使得离摄像机越近的物体具有更加丰富的细节，而远离摄像机的物体具有较少的细节。

**几何着色器**：几何着色器也是渲染管线一个可选的阶段。我们知道，顶点着色器的输入是单个顶点以及其属性，输出的是经过变换后的顶点。与顶点着色器不同，几何着色器的输入是完整的图元(比如点)，输出可以是一个或多个其他的图元(比如三角面)，或者不输出任何的图元。几何着色器的主要用途就是将输入的点或线扩展成多边形。

**图元组装**：图元组装将输入的顶点组装成指定的图元。图元组装阶段会进行裁剪和背面剔除相关的优化，以减少进入光栅化的图元的数量，加速渲染过程。在光栅化之前，还会进行屏幕映射的操作：透视除法和视口变换。

**光栅化**：经过图元组装以及屏幕映射阶段后，我们将物体坐标变换到了窗口坐标。光栅化是个离散化的过程，将3D连续的物体转化为离散屏幕像素点的过程。包括三角形组装和三角形遍历两个阶段。光栅化会确定图元所覆盖的片段，利用顶点属性插值得到片段的属性信息，然后送到片段着色器进行颜色计算。这里需要注意到片段是像素的候选者，只有通过后续的测试，片段才会成为最终显示的像素点。

![光栅化](/Users/lingxin/Desktop/pathTracing/光栅化.png)

**片元着色器（像素着色器）**：片段着色器用来决定屏幕上像素的最终颜色。在这个阶段会进行光照计算以及阴影处理，是渲染管线高级效果产生的地方。通过自定义片元着色器，可以实现很多酷炫的光影效果。本文中，路径追踪算法实现的就是位于片元着色器中。

**测试混合阶段**：管线的最后一个阶段是测试混合阶段。测试包括裁切测试、Alpha测试、模板测试和深度测试。没有通过测试的片段会被丢弃，不需要进行混合阶段；经过测试的片段会进入混合阶段。Alpha混合可以根据片段的alpha值进行混合，用来产生半透明的效果。Alpha表示的是物体的不透明度，因此alpha=1表示完全不透明，alpha=0表示完全透明。测试混合阶段虽然不是可编程阶段，但是我们可以通过图形管线提供的接口进行配置，定制混合和测试的方式。

## 光栅化与光线追踪

当考虑渲染一个3D场景时，我们会自然而然地想到模仿真实世界的光线传播，沿着这种思想推导，我们得到了光线追踪。光线追踪需要大量计算。从历史上看，计算机硬件的速度还不够快，想要使用光线追踪渲染场景需要消耗较长的时间。对于电影，制作人为了一帧精美的画面，愿意也经得起花费好几个小时来渲染。但游戏中的一帧只有几分之一秒，无法进行大量计算，因此，大多数实时图形都依赖于另一种技术，即光栅化。

### 光栅化

这里的光栅化指的是渲染场景的一种方法，它的主要功能是对片元进行着色，与渲染流水线的光栅化区分。

在渲染3D场景是，光栅化是最常见的算法。***它有着非常长久的历史***。光栅化的方法也不只一种，下面主要介绍的是本项目中采用的Blinn-Phong模型。

Blinn-Phong模型将场景中的光分为三种：

1. 环境光：可以理解为场景的底色，即使没有光线直接照射到物体，物体还是会有一个基本的强度，让物体不至于不可见。但环境光不能很好地表示物体的边界，只应用环境光不能反映物体的深度信息，从渲染结果上看，就是整个物体糊成一团。

   Blinn-Phong模型对环境光的实现较为简单，即在片元着色器中为每个片元的着色添加一个基础亮度。

2. 漫反射：即光线射到物体表面发生反射，各个方向反射光的强度都相同。应用漫反射可以很好地反映出物体边界和深度信息。但对于一些存在高光的材质，如玻璃、金属，漫反射还不足以模仿其效果。

   （贴图）

   Blinn-Phong模型对漫反射的实现做了一个取巧。。。。

3. 镜面反射：镜面反射指光线射到光滑表面发射反射，反射光只分布在一个较小的角度内。在这个角度之外看，表面是暗淡的；在这个角度之内看，可以看到表面是明亮的，形成高光现象。应用镜面反射，我们就可以模拟玻璃、金属等存在高光的物体。

   Blinn-Phong模型对镜面反射的实现是：。。。

综合以上三点，得出Blinn-Phong光照模型公式：。。。



### 光线追踪

光线追踪是一种模拟光的物理行为的图形渲染方法。***光线追踪技术于 1969 年首次概念化，多年来一直用于模拟电影行业中逼真的光照和阴影。***它模拟光线在现实世界中反射和折射的方式，提供比在更传统的游戏中使用静态照明通常看到的环境更真实的环境。

![光线追踪效果对比](/Users/lingxin/Desktop/pathTracing/光线追踪效果对比.png)

想到光线追踪最简单的方法就是现在环顾四周。你看到的物体被光束照亮。现在把它转过来，沿着这些光束的路径从你的眼睛向后返回到与光相互作用的物体。这就是光线追踪。

在现实生活中，光线是由周围环境射向人的眼球。光源发出无数光线，光线命中物体表面发生反射，反射光线又命中物体再次发生反射，直到最后正中人的眼球。然后，大脑将所有这些不同的光线解释为一幅完整的图片。

光线追踪的原理和光传播的原理相似，只是光线是按相反方向传播的。在光线追踪中，光从观察者出发（本质上是从相机射出，以相机与投影平面上的某一点确定一条直线，光线就沿此方向传播）并向外传播，绘制出一条在多个物体之间反射的路径，有时会携带上反射点的颜色和反射特性（用于影响下一个反射点的着色），直到命中光源。这种向后模拟视觉的技术对于计算机来说比试图追踪来自光源的光线要更加现实。

（加光线追踪原理图）

## 辐射度量学

https://ksgfk.github.io/2021/02/26/%E5%9B%BE%E5%BD%A2-%E8%BE%90%E5%B0%84%E5%BA%A6%E9%87%8F%E5%AD%A6/

（辐射度量学定义）

### 辐射度量学物理量

首先明确几个辐射度量学的基本概念。

https://juejin.cn/post/7141948365650001956

#### 辐射能量

在辐射度量学中最基本的单位是辐射能量，表示为*Q*,单位是J*(焦耳)，辐射能量*Q以辐射的形式发射，传播或接收的能量。每个光子都携带一定的能量，这个能量正比于它的频率：
$$
Q = hv \\
其中h=6.62620×(10−34)J
$$
光子的频率（或者说能量）影响着光子与物体表面的交互，更重要的是，它影响着光与感应器之间的作用，使不同频率的光被察觉为不同的颜色。

#### 辐射通量

辐射通量，记为为Φ，表示单位时间流过的能量（包括发射、反射、传播、接受）(功率-power)。单位为W（watt）或者lm（lumen）。我们使用辐射通量来测量辐射，其与辐射能量的关系：
$$
Φ = \frac{dQ}{dt}
$$

#### 辐射强度

辐射强度，记为*I*，表示一个点光源在单位立体角上发射能量的功率，即光源在某一方向上的辐射功率。单位为cd（candela）。

在辐射度两学里，通常用$ω\omegaω$表示三维空间中的一个方向。$ω\omegaω$可以用$θ$和$ϕ\theta$和$\phiθ$和$ϕ$两个参数定义它的位置。并且可以通过$sin⁡θdθdϕ\sin\theta{d}\theta{d}\phisinθdθdϕ$表示它的单位立体角。则辐射强度的数学定义如下：
$$
I(w) = \frac{d\Phi}{dw}
$$

#### 辐射照度

辐射照度记为*E*，表示单位投影面积的能量功率，用于描述物体表面单位面积接收到的辐射功率，单位为lux。其数学定义如下：
$$
E(x) = \frac{d\Phi(x)}{dA} \\ 
其中A为面积
$$

#### 辐射亮度

辐射亮度表示为单位投影面积、单位立体角被发射/反射/转换/接收的辐射功率，记为*L*，单位为nit。

![辐射亮度](/Users/lingxin/Desktop/pathTracing/辐射亮度.png)

以上图为例，点p处的辐射亮度定义如下：
$$
L(p,w) = \frac{d^2\Phi(p,w)}{dwdA\cos\theta}
$$

### 渲染方程

。。。

### 蒙特卡洛积分

（蒙特卡洛方法定义）

蒙特卡罗方法是一种计算方法。原理是通过大量随机样本，去了解一个系统，进而得到所要计算的值。

## 路径追踪

（光线追踪的缺点）

为了解决这些问题，Kajiya (1986) 在首次描述光传输方程的同一篇论文中提出了路径追踪方法。路径追踪是第一个用于图形的通用无偏蒙特卡洛光传输算法。 路径追踪以增量方式生成从相机开始到场景中光源结束的散射事件的路径。现在，路径追踪已经被广泛应用于游戏电影行业，用于生产高质量图像。其性能优于传统的光线追踪，能在更短时间内渲染出质量更高的图像。其与光线追踪、光栅化的渲染效果对比如下图：

![路径追踪效果对比jpg](/Users/lingxin/Desktop/pathTracing/路径追踪效果对比jpg.jpg)

（路径追踪原理，与前面光追缺点对应）

（路径追踪方法下的渲染方程）







## 优化



### 均匀采样

https://jcgt.org/published/0009/04/01/

在路径追踪算法的实现中，我们需要在反射点周围进行采样。为了让采样结果符合真实值，采样点的必须要均匀分布。

一个容易想到的方法是使用随机数。glsl中没有随机数发生函数，为了进行随机采样，我们需要从外部传入生成好的随机数。***但问题是js生成的随机数不是真随机数，其受到时间影响。***使用这种随机数进行采样，采样点的不是真正均匀分布，得到的结果会具有较大的噪声。

让我们转化一下思路，我们使用随机数最终期望的是让采样变得均匀，那么我们未必需要使用随机数，只要最后所有采样点是满足均匀分布的。本文使用sobol序列来实现该效果。

#### Radical Inversion与Van der Corput序列

Van der Corput序列的定义如下：
$$
\Phi_{b,C}(i) = (b^{-1}...b^{-M})[C(a_0(i)...a_{M-1}(i))^T]
$$
b是一个正整数，则任何一个整数i如果先将i表示成b进制的数，然后把得到的数中的每一个位上的数字$a_l(i)$排成一个向量，和一个生成矩阵C相乘得到一个新的向量，最后再把这个新向量中镜像到小数点右边去就能得到这个数以b为底数，以C为生成矩阵的Radical Inversion序列。

Van der Corput序列则是用单位矩阵替换Radical Inversion序列中的生成矩阵C：
$$
\Phi_b(i) = (b^{-1}...b^{-M})(a_0(i)...a_{M-1}(i))^T = \sum^{M-1}_{l=0}a_l(i)b^{-l-1}
$$
对于正整数8，其以2为底的Van der Corput序列项的计算过程如下：

+ 计算8的二进制表示1000；
+ 将1000镜像到小数点右边，得0.0001；
+ 将0.0001转化为十进制，得到0.0625，即$\Phi_2(8) = 0.0625$

#### Sobol序列

Sobol序列的每一个维度都是由底数为2的radical inversion序列组成，但每一个维度的radical inversion序列都有各自不同的矩阵，其定义如下：
$$
X_i := (\Phi_{2,C_1}(i),...,\Phi_{2,C_n}(i))
$$
因为完全以2为底数，所以Sobol序列的生成可以直接使用bit位操作实现radical inversion，非常高效。其生成的点集如下图所示：

<img src="/Users/lingxin/Desktop/pathTracing/sobol序列.png" alt="sobol序列" style="zoom:50%;" />

项目使用shadertoy上提供的sobol序列生成器。

### 泛光问题

https://moontree.github.io/2020/08/30/tone-mapping/

（图片）

要了解泛光问题的出现原因，先要了解HDR和LDR的概念。

#### HDR

HDR(High Dynamic Range)指的是高动态范围。

其中的Dynamic Range是一种用数学方式来描述某个给定场景的亮度层次范围的技术术语。 指图像中所包含的从“最亮”至“最暗”的比值，也就是图像从“最亮”到“最暗”之间灰度划分的等级数； 动态范围越大，所能表示的层次越丰富，所包含的色彩空间也越广。

计算机图形学中通常使用的直接以场景最高亮度和最低亮度的亮度比表述的方法，如255:1。 我们渲染出的图像就属于HDR。

#### LDR

LDR(High Dynamic Range)指的是低动态范围。它所采用的色彩模型是目前通用的图像描述模型——RGB模型。 每种色彩都可以用三原色（红、绿、蓝）加上适当的亮度来表示，三原色的亮度梯度各为256级。本项目中的LDR对应的是屏幕。

泛光现象出现的原因是直接将HDR的渲染结果线性映射到了LDR的屏幕上。由于人眼的视觉特性，对低亮度的敏感程度大于对高亮度的敏感程度，从HDR到LDR的线性映射会导致生成的图像的高亮部分变得模糊，最终呈现的就是泛光现象。

本文引入toneMapping来解决泛光问题。

图像由像素组成，每个像素都有一种颜色，包括黑色和白色。toneMapping是一种数字图像处理技术，用于修改像素的色调值。换句话说，toneMapping会调整具有高动态范围的图像的色调值，将其映射到低动态范围的显示器上，同时符合人眼的视觉特性，让图像保留原始外观。

（Reinhard的论文“Photographic Tone Reproduction for Digital Images”，参考了已有的摄影师对图像的处理过程，提出了对数字图像进行处理的tone mapping算法。算法基于Zone System的概念框架，首先进行类似设定相机曝光的缩放，其次是局部的dodging-and-burning。）

Three.js中内置了toneMapping处理器——ACESFilmicToneMapping。为WebGLRenderer设置属性toneMapping为ACESFilmicToneMapping即可解决泛光问题。

（toneMapping之后的图片）

### 俄罗斯轮盘赌

https://www.pbr-book.org/3ed-2018/Monte_Carlo_Integration/Russian_Roulette_and_Splitting

（俄罗斯轮盘赌的提出）

俄罗斯轮盘赌是一种简化采样的技巧，它通过增加每个样本对结果产生重大贡献的可能性，来提升蒙特卡洛积分的效率。俄罗斯轮盘赌实际上分为轮盘赌和分割两部分。轮盘赌用户处理获取样本成本高但对最终结果贡献小的问题。分割是一种技术，能够将更多样本放在积分的重要维度上。

我们可以使用俄罗斯轮盘赌解决路径追踪中，光线弹射次数过多的问题。首先设定一个概率P，有P的概率光线会继续递归并设置返回值为L/P，有1−P的概率光线停止递归，并返回0。这样巧妙的设定之下光线一定会在某次反射之后停止递归，并且计算的结果依然是无偏的，因为Radiance的期望不变，证明如下：
$$
E = P(L/P)+0*(1-P) = L
$$
本项目中，设置概念P与反射点的亮度有关。伪代码如下：

```

```





（代码的原理）

### 多重要性采样

https://graphics.stanford.edu/courses/cs348b-03/papers/veach-chapter9.pdf

如图，使用路径追踪算法渲染出的结果中出现了较多白点，这种现象又被称之为“火萤”。火萤现象严重意味着图像中的高光点多，渲染效果不好。

火萤现象出现的原因在于反射光线的采样。反射光线从反射点射出，命中情况有三种：未命中、命中光源、命中物体。

未命中，即命中环境贴图，较好处理，只需根据将命中点映射到环境贴图上，采样即可得到反射点着色。环境贴图表示的是从四面八方射向场景的光，其实也可以看作光源，这里为了与场景中的光源做区分，将其单独分类。但环境贴图中的高亮部分也可能导致火萤现象出现，这里做一个约定，即命中环境贴图中高亮的部分也被称之为命中光源。

火萤现象出现的主要原因是命中光源与命中物体两种情况，对反射点着色的贡献程度没有做区分。光源的亮度通常要高于场景中的物体，反射光线命中光源时，会以一个高亮度着色反射点；命中物体的反射光线会以一个较低的亮度着色反射点。这两者没有区分，这就导致点A采样后，反射光线命中光源，呈现高亮度，其周围点采样命中物体，呈现低亮度，最终点A的亮度要明显高于周围，在画面上就是一个白点。

本项目使用多重要性采样解决缓解火萤问题。

多重要性采样的技术可以大大提高蒙特卡洛积分的可靠性和效率。它基于多种采样技术评估给定的积分，并使用一种被证明可靠的方式将采样值结合起来。使用多重要性采样的动机是计算机图形学中的大多数数值积分问题都是困难的，即被积函数是不连续的、高维的或奇异的。 我们想设计一种采样策略，以给出积分的低方差估计。本项目中采用简单的加权平均来确定权重。

本项目中，多重要性采样用于决定解决路径追踪采样中，反射光线命中光源和命中物体两种情况的权重。

多重要性采样计算权重的函数如下：

```glsl
float misHeuristic( float a, float b ) {
		float aa = a * a;
		float bb = b * b;
		return aa / ( aa + bb );
	}
```

其中两个参数a、b应分别是散射表面的pdf和光源的pdf。

### 性能优化

实现路径追踪的算法主要实现位于片元着色器中，其中有大量计算，而GPU在着色时会同时对大量片元进行着色，此时GPU的负载就非常大。如果GPU的配置不高，就很容易发生卡顿现象，影响用户体验。

为了优化算法性能、减少卡顿，我们需要减少GPU一次着色的片元数量。本项目采用屏幕分割的方法，将屏幕上的像素分为多块，每次渲染时，只将一块区域内的像素传给GPU进行着色。这种方式处理过后，屏幕上展示的图像将是每一帧只变化1小块，又上至下、从左往右一块块更新。

本项目采用three.js提供的FullScreenQuad库实现屏幕分割，其能读取传入的渲染器对象的裁剪信息，自动将上一帧图像与裁剪区域渲染后的图像融合。使用方式如下：

1. 初始化WebGl渲染器，renderer；
2. 实例化一个FullScreenQuad对象，本项目中将其命名为fsQuad；
3. 暂存renderer的启用裁剪状态和视窗尺寸；
4. 为renderer设置裁剪位置和尺寸、视窗尺寸，这一帧需要渲染的屏幕块由裁剪信息指定；
5. 将renderer传入fsQuad进行渲染，裁剪区域内的像素就会被GPU着色，呈现的结果就是图像上有一块区域更新。

（贴图）





